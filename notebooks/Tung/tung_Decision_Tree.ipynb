{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statistics as stat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "df_original = pd.read_csv(\"https://raw.githubusercontent.com/alvarofavale/week7_ml/refs/heads/main/data/raw/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original.copy()\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df[df[\"customer_id\"] == 3392]\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.credit_score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"ssn\", \"name\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limit = df.sample(1000)\n",
    "#sns.pairplot(df_limit, hue =\"Credit_Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_limit.drop(columns = [\"credit_score\"])\n",
    "features = features.select_dtypes(include = \"number\")\n",
    "target = df_limit[\"credit_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.replace({\"Good\" : 1, \"Standard\" : 2, \"Poor\" : 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler()\n",
    "\n",
    "normalizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm_np = normalizer.transform(X_train)\n",
    "\n",
    "X_test_norm_np = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm_df = pd.DataFrame(X_train_norm_np, columns = X_train.columns, index=X_train.index)\n",
    "X_train_norm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm_df = pd.DataFrame(X_test_norm_np, columns = X_test.columns, index=X_test.index)\n",
    "X_test_norm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standarized_np = scaler.transform(X_train)\n",
    "X_test_standarized_np = scaler.transform(X_test)\n",
    "\n",
    "X_train_standarized_df = pd.DataFrame(X_train_standarized_np, columns = X_train.columns, index=X_train.index)\n",
    "X_test_standarized_df  = pd.DataFrame(X_test_standarized_np, columns = X_test.columns, index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training the model\n",
    "\n",
    "Note: Decision Trees are not \"distance\" based models. Therefore, we don't need to have the data before training them. If we do so, the model with adapt to the new transformed data and the changes in the predictions will be small.\n",
    "\n",
    "Here, for simplicity we will train a Decision Tree with transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.replace({\"Good\" : 1, \"Standard\" : 2, \"Poor\" : 3}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(X_train_norm_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.replace({\"Good\" : 1, \"Standard\" : 2, \"Poor\" : 3}, inplace=True)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_dt = tree.predict(X_test_norm_df)\n",
    "\n",
    "print(f\"MAE, {mean_absolute_error(y_pred_test_dt, y_test): .2f}\")\n",
    "print(f\"RMSE, {mean_squared_error(y_pred_test_dt, y_test, squared=False): .2f}\")\n",
    "print(f\"R2 score, {tree.score(X_test_norm_df, y_test): .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we check what are the most relevant features, like we did before in Linear Regression. However, here we don't have coefficients. Therefore, to do this kind of analisys, we check in which order were the features selected to split the data. The intuition behind this method is that the most important features will be selected first, while less important fetures will be used in later splits.\n",
    "\n",
    "Fortunatelly for us, this information in stored in the instance of the class and it can be accessed trough the attribute `.feature_importances_` once the model has been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_importance = {feature : importance for feature, importance in zip(X_train_norm_df.columns, tree.feature_importances_)}\n",
    "tree_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "tree_viz = export_text(tree, feature_names=list(X_train_norm_df.columns))\n",
    "print(tree_viz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit overwhelming to see, let's use graphviz library.\n",
    "\n",
    "**Note**: you will need to install graphivz\n",
    "\n",
    "* pip install graphviz\n",
    "* conda install graphviz -y\n",
    "\n",
    "depending on your environment and package mannager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will train a decision tree, in this case with max_depth=2 to better see the diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "import graphviz\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=2)\n",
    "tree.fit(X_train_norm_df, y_train)\n",
    "\n",
    "\n",
    "dot_data = export_graphviz(tree, out_file=\"tree.dot\", filled=True, rounded=True, feature_names=X_train_norm_df.columns)\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example data (Replace this with your actual dataset)\n",
    "data = {\n",
    "    'income': [50000, 40000, 80000, 60000, 75000, 120000, 95000, 110000, 45000, 60000],\n",
    "    'debt': [20000, 15000, 50000, 25000, 40000, 30000, 35000, 20000, 18000, 22000],\n",
    "    'credit_score': [2, 0, 2, 1, 2, 2, 1, 2, 0, 1]  # Already encoded as 0, 1, 2\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and target\n",
    "X = df[['income', 'debt']]\n",
    "y = df['credit_score']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features (optional, but useful for some models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a classifier (RandomForest in this case)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate a meshgrid to define the decision boundary\n",
    "x_min, x_max = X['income'].min() - 1000, X['income'].max() + 1000\n",
    "y_min, y_max = X['debt'].min() - 1000, X['debt'].max() + 1000\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 500),\n",
    "                     np.arange(y_min, y_max, 500))\n",
    "\n",
    "# Predict the class for each point in the grid\n",
    "Z = model.predict(scaler.transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdYlGn)  # Red for bad, Yellow for standard, Green for good\n",
    "\n",
    "# Plot the actual data points on top\n",
    "sns.scatterplot(x='income', y='debt', hue='credit_score', data=df, palette={0: 'red', 1: 'orange', 2: 'green'},\n",
    "                s=100, edgecolor='black')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Credit Score Decision Regions (Good, Standard, Bad)')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Debt')\n",
    "plt.legend(title='Credit Score', labels=['Bad', 'Standard', 'Good'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target (assuming the target column is 'credit_score')\n",
    "X = dfc[['income', 'debt', 'some_other_feature']]  # Replace 'some_other_feature' with actual features\n",
    "y = dfc['credit_score']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Create a meshgrid for decision boundaries\n",
    "x_min, x_max = X['income'].min() - 1000, X['income'].max() + 1000\n",
    "y_min, y_max = X['debt'].min() - 1000, X['debt'].max() + 1000\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 500),\n",
    "                     np.arange(y_min, y_max, 500))\n",
    "\n",
    "# Predict the class for each point in the grid\n",
    "Z = clf.predict(scaler.transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdYlGn)  # Adjust colors for each class (Good, Standard, Bad)\n",
    "\n",
    "# Plot the actual data points\n",
    "sns.scatterplot(x='income', y='debt', hue='credit_score', data=dfc, palette={0: 'red', 1: 'yellow', 2: 'green'},\n",
    "                s=100, edgecolor='black')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Decision Boundary for Credit Score Prediction')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Debt')\n",
    "plt.legend(title='Credit Score', labels=['Bad', 'Standard', 'Good'])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
